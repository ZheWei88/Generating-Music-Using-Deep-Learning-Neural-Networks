{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14bf93b9",
   "metadata": {},
   "source": [
    "# Music Generation\n",
    "The notebook will serve to generate music from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e75ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import instrument, note, stream, chord\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
    "from tensorflow.keras.layers import Activation, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf4a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the original dataset first\n",
    "\n",
    "\n",
    "# import note stuff\n",
    "\n",
    "with open('../assets_notes_times/notes', 'rb') as filepath:\n",
    "    notes = pickle.load(filepath)\n",
    "\n",
    "with open('../assets_notes_times/note_to_int', 'rb') as filepath:\n",
    "    note_to_int = pickle.load(filepath)\n",
    "    \n",
    "with open('../assets_notes_times/song_notes', 'rb') as filepath:\n",
    "    song_notes = pickle.load(filepath)\n",
    "    \n",
    "\n",
    "# import time stuff\n",
    "\n",
    "with open('../assets_notes_times/time', 'rb') as filepath:\n",
    "    time = pickle.load(filepath)\n",
    "\n",
    "with open('../assets_notes_times/time_to_int', 'rb') as filepath:\n",
    "    time_to_int = pickle.load(filepath)\n",
    "    \n",
    "with open('../assets_notes_times/song_times', 'rb') as filepath:\n",
    "    song_times = pickle.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b23ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the song_notes and song_times for test dataset\n",
    "with open('../assets_test_songs/song_notes', 'rb') as filepath:\n",
    "    test_song_notes = pickle.load(filepath)\n",
    "        \n",
    "with open('../assets_test_songs/song_times', 'rb') as filepath:\n",
    "    test_song_times = pickle.load(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5023211",
   "metadata": {},
   "source": [
    "## Prepare Prediction Input\n",
    "\n",
    "Create 2 different inputs using the test song data\n",
    "- **network_input**: the list of 100-note inputs to randomize for prediction\n",
    "- **model_input**: to recreate the training model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0465f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_input(some_notes_train, some_notes_test, something_to_dict):\n",
    "    # some_notes will be the song_notes/song_times of the test dataset songs\n",
    "    # something_to_dict is the note_to_int/time_to_int\n",
    "\n",
    "    sequence_length = 100\n",
    "    network_input = []\n",
    "    \n",
    "    for element in some_notes_test:\n",
    "    \n",
    "        for i in range(0, len(element) - sequence_length, 1):\n",
    "            sequence_in = element[i:i + sequence_length]\n",
    "            sequence_out = element[i + sequence_length]\n",
    "            network_input.append([something_to_dict.get(char,0) for char in sequence_in])\n",
    "            #.get(char,0) defaults to key 0, which is the 'unkw' value.\n",
    "            # this ensures that if note/duration does ot exist in the test data, it will default to 'unkw'.\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    \n",
    "    model_input = []\n",
    "    for element in some_notes_train:\n",
    "    \n",
    "        for i in range(0, len(element) - sequence_length, 1):\n",
    "            sequence_in = element[i:i + sequence_length]\n",
    "            sequence_out = element[i + sequence_length]\n",
    "            model_input.append([something_to_dict.get(char,0) for char in sequence_in])\n",
    "    \n",
    "    n_patterns = len(model_input)\n",
    "            \n",
    "    model_input = np.reshape(model_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "    return (network_input, model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52adefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare note inputs\n",
    "network_input_notes, model_input_notes = prediction_input(song_notes, test_song_notes, note_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1667bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare duration inputs\n",
    "network_input_times, model_input_times = prediction_input(song_times, test_song_times, time_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e8be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84424\n",
      "53167\n",
      "84424\n",
      "53167\n"
     ]
    }
   ],
   "source": [
    "print(len(network_input_notes))\n",
    "print(len(model_input_notes))\n",
    "print(len(network_input_times))\n",
    "print(len(model_input_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61907814",
   "metadata": {},
   "source": [
    "## Recreating the Model Architecture\n",
    "This will allow us to load the trained model weights and get the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1987fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(model_input, vocab):\n",
    "    # re-create the structure of the neural network\n",
    "    # vocab is the n_vocab/t_vocab\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(\n",
    "        vocab,\n",
    "        512,\n",
    "        input_length=100,\n",
    "    ))\n",
    "    model.add(Bidirectional(LSTM(\n",
    "        512,\n",
    "        recurrent_dropout=0,\n",
    "        return_sequences=True\n",
    "    )))\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True, recurrent_dropout=0,)))\n",
    "    model.add(Bidirectional(LSTM(512)))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0471bc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n",
      "174\n"
     ]
    }
   ],
   "source": [
    "# notes vocab\n",
    "n_vocab = len(note_to_int)\n",
    "print(n_vocab)\n",
    "\n",
    "# duration vocab\n",
    "t_vocab = len(time_to_int)\n",
    "print(t_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280cea6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 512)          196096    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100, 1024)        4198400   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 100, 1024)        6295552   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 1024)             6295552   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1024)             4096      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               262400    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 383)               98431     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 383)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,351,551\n",
      "Trainable params: 17,348,991\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# recreate notes model\n",
    "model_notes = create_network(model_input_notes, n_vocab)\n",
    "model_notes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c479108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load note weights\n",
    "# model_notes.load_weights('../weights/notes/weights-09-1.8850.hdf5') # 50% accuracy\n",
    "# model_notes.load_weights('../weights/notes/weights-15-0.6089.hdf5') # 80% accuracy\n",
    "# model_notes.load_weights('../weights/notes/weights-19-0.3403.hdf5') # 90% accuracy\n",
    "model_notes.load_weights('../weights/notes/weights-58-0.1027.hdf5') # 97% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad8a13f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 512)          89088     \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 100, 1024)        4198400   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 100, 1024)        6295552   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 1024)             6295552   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 174)               44718     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 174)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,190,830\n",
      "Trainable params: 17,188,270\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# recreate notes model\n",
    "model_time = create_network(model_input_times, t_vocab)\n",
    "model_time.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab941f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load duration weights\n",
    "# model_time.load_weights('../weights/times/weights-01-2.2547.hdf5') # 50% accuracy\n",
    "# model_time.load_weights('../weights/times/weights-21-0.6097.hdf5') # 80% accuracy\n",
    "# model_time.load_weights('../weights/times/weights-28-0.3240.hdf5') # 90% accuracy\n",
    "model_time.load_weights('../weights/times/weights-52-0.0870.hdf5') # 97% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b0c16",
   "metadata": {},
   "source": [
    "## Generate Notes\n",
    "We will generate 100 notes/chrods and durations. To start us off, we are randomly selecting one of our 100-note inputs from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7728a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pitchnames and timenames\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "pitchnames.insert(0,'unkw')\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "timenames = sorted(set(item for item in time))\n",
    "timenames.insert(0,'unkw')\n",
    "int_to_time = dict((number, time) for number, time in enumerate(timenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c5e529",
   "metadata": {},
   "source": [
    "The first note generation technique invloves generating a note/chord or duration, and putting this generated note back into the input sequence, which is then used to predict the next note. Repeat the process as many times as you want the length of the song to be.\n",
    "\n",
    "I find that this works best for note/chord generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4998e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(model, network_input, int_to_something, start, song_length):\n",
    "\n",
    "    # start - pick a random 100-note training input to start off our prediction\n",
    "    pattern = network_input[start] # every element is a 100 note sequence\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate notes\n",
    "    for note_index in range(song_length):\n",
    "        # reshape 1 record of prediction input and predict the output\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "     \n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        # Return the index of the output vector with the highest value\n",
    "        index = np.argmax(prediction)\n",
    "        # Map the predicted integer back to the corresponding note \n",
    "        result = int_to_something[index]\n",
    "        # Store the predicted note into an output list and append the predicted note to the initial training input\n",
    "        prediction_output.append(result)\n",
    "        pattern.append(index)\n",
    "        # Drop the first note and keep the latest 100 note for the next note prediction cycle \n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1281c45",
   "metadata": {},
   "source": [
    "The second note generation technique invloves not inserting the generated notes back into the input, but rather shift the input song by one note with each cycle.\n",
    "\n",
    "I find this works best for duration generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "867450d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_2(model, network_input, int_to_something, start, song_length):\n",
    "\n",
    "    # start - pick a random 100-note training input to start off our prediction\n",
    "    pattern = network_input[start] # every element is a 100 note sequence\n",
    "    prediction_output = []\n",
    "    count = 0\n",
    "\n",
    "    # generate notes\n",
    "    for note_index in range(song_length):\n",
    "        # reshape 1 record of prediction input and predict the output\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "     \n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        # Return the index of the output vector with the highest value\n",
    "        index = np.argmax(prediction)\n",
    "        # Map the predicted integer back to the corresponding note \n",
    "        result = int_to_something[index]\n",
    "        # Store the predicted note into an output list and append the predicted note to the initial training input\n",
    "        prediction_output.append(result)\n",
    "        # Shift the input song by 1 note and keep the latest 100 note for the next note prediction cycle \n",
    "        count+=1\n",
    "        pattern = network_input[(start+count)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d799755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the start\n",
    "start = np.random.randint(0, len(network_input_notes)) # both notes and time input have same length\n",
    "\n",
    "# set song_length\n",
    "song_length = 100\n",
    "\n",
    "# get the predicted notes\n",
    "prediction_notes = generation(model_notes, network_input_notes, int_to_note, start, song_length)\n",
    "\n",
    "# get the predicted duration\n",
    "prediction_times = generation(model_time, network_input_times, int_to_time, start, song_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ce6c29",
   "metadata": {},
   "source": [
    "## Generate MIDI\n",
    "Finally, we can generate the MIDI file! We will combine the predicted notes together with the durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbadfba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to turn the string durations back into float\n",
    "def convert_to_float(frac_str):\n",
    "    try:\n",
    "        return float(frac_str)\n",
    "    except ValueError:\n",
    "        num, denom = frac_str.split('/')\n",
    "        try:\n",
    "            leading, num = num.split(' ')\n",
    "            whole = float(leading)\n",
    "        except ValueError:\n",
    "            whole = 0\n",
    "        frac = float(num) / float(denom)\n",
    "        return whole - frac if whole < 0 else whole + frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "060ac42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_notes, prediction_times):\n",
    "#     offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for n in range(len(prediction_notes)): # length of predicted notes is same as length of predicted time\n",
    "        pattern_note = prediction_notes[n]\n",
    "        duration = prediction_times[n]\n",
    "        pattern = pattern_note\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes, quarterLength=convert_to_float(duration))\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a rest\n",
    "        elif('rest' in pattern):\n",
    "#             pass\n",
    "            new_rest = note.Rest(pattern, quarterLength=convert_to_float(duration))\n",
    "            new_rest.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_rest)\n",
    "        else:\n",
    "            new_note = note.Note(pattern, quarterLength=convert_to_float(duration))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "\n",
    "#     midi_stream.write('midi', fp='../midi_generate_classical/50%.mid') # 50% accuracy\n",
    "#     midi_stream.write('midi', fp='../midi_generate_classical/80%.mid') # 80% accuracy\n",
    "#     midi_stream.write('midi', fp='../midi_generate_classical/90%.mid') # 90% accuracy\n",
    "    midi_stream.write('midi', fp='../midi_generate_classical/97%.mid') # 97% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d40122a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_midi(prediction_notes, prediction_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf6534",
   "metadata": {},
   "source": [
    "## Generated Music\n",
    "\n",
    "Thanks to the weights of the model, we are able to see the progress of the music generation at various stages of the training:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5822592",
   "metadata": {},
   "source": [
    "### 50% accuracy\n",
    "\n",
    "https://soundcloud.com/zhe-wei-3/50a?utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing\n",
    "\n",
    "As can be heard, the generated music is very repetitive, with only slight variations in the notes and no variation in the durations. This can be expected as it is still very early in the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77cecc",
   "metadata": {},
   "source": [
    "### 80% accuracy\n",
    "\n",
    "https://soundcloud.com/zhe-wei-3/80a?utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing\n",
    "\n",
    "This generated music is slighlty better, with more variation in the notes and durations, but still prone to repetitive patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f39b96",
   "metadata": {},
   "source": [
    "### 90% accuracy\n",
    "\n",
    "https://soundcloud.com/zhe-wei-3/90a?utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing\n",
    "\n",
    "This song starts out strong, with some interesting ideas at the start. Much more melodic and complex than the last 2, it nevertheless falls back to some repetition towards the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c716f",
   "metadata": {},
   "source": [
    "### 97% accuracy\n",
    "\n",
    "https://soundcloud.com/zhe-wei-3/97a?utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing\n",
    "\n",
    "This is the most musical piece out of the 4. It has motifs, with the repeated patterns gradually change from one to another, showing a high degree of musical literacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be933574",
   "metadata": {},
   "source": [
    "### Best Songs\n",
    "\n",
    "These are a collection of some of the best and most interesting generations from the model. I used the **generation** function for the notes/chords, and the **generation_2** function for thr durations. Enjoy!\n",
    "\n",
    "#### Emotional\n",
    "https://soundcloud.com/zhe-wei-3/emotional?utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing\n",
    "\n",
    "#### Fast\n",
    "https://soundcloud.com/zhe-wei-3/fast?utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing\n",
    "\n",
    "#### Happy\n",
    "https://soundcloud.com/zhe-wei-3/happy?utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing\n",
    "\n",
    "#### Melodic\n",
    "https://soundcloud.com/zhe-wei-3/melodic?utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing\n",
    "\n",
    "#### Moody\n",
    "https://soundcloud.com/zhe-wei-3/moody?utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3ce5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
